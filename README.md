# AI-Powered Exam Generation System

An intelligent system that analyzes exam bank data and generates new exam questions using machine learning.

## ğŸ¯ Project Status

**Current Phase**: Model Building & Analysis

You have successfully extracted and organized exam data. The project is now focused on building machine learning models to understand exam patterns and generate new questions.

## ğŸ“ Project Structure

```
Parse_Files/
â”œâ”€â”€ data/                      # Data files
â”‚   â”œâ”€â”€ exam_analysis.json     # Extracted exam questions (201 questions from 13 exams)
â”‚   â””â”€â”€ exam_downloads/        # Original PDF files
â”‚
â”œâ”€â”€ models/                    # Machine Learning Models
â”‚   â”œâ”€â”€ README.md             # Model building guide
â”‚   â”œâ”€â”€ build_first_model.py  # Starter script for first ML model
â”‚   â””â”€â”€ check_current_data.py # Dataset analysis tool
â”‚
â”œâ”€â”€ exam_analysis/            # Data Processing & Cleaning
â”‚   â”œâ”€â”€ enhanced_extractor.py # PDF text extraction with OCR support
â”‚   â”œâ”€â”€ data_cleaner.py       # Data cleaning pipeline
â”‚   â”œâ”€â”€ run_cleaning.py       # Run data cleaning
â”‚   â””â”€â”€ DATA_CLEANING_GUIDE.md
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ PROJECT_GOALS.md      # Project objectives and vision
â”‚   â”œâ”€â”€ IMPLEMENTATION_ROADMAP.md  # Step-by-step implementation guide
â”‚   â””â”€â”€ PROJECT_STRUCTURE.md  # Technical structure
â”‚
â”œâ”€â”€ queens_exam_env/          # Python virtual environment
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # This file
```

## ğŸš€ Quick Start

### 0. Extract Cover Page Metadata (New!)
```bash
python extract_cover_page_metadata.py
```
Extracts metadata from exam cover pages: faculty, professor, course name, total marks, and dates.
Automatically detects OCR settings needed for each exam type (language, math, etc.).
See `docs/COVER_PAGE_EXTRACTION_GUIDE.md` for details.

### 1. Calculate Difficulty Scores
```bash
python calculate_difficulty.py
```
Calculates difficulty scores based on question marks: `difficulty_score = question_marks / total_exam_marks`
Now prefers total marks from cover page (more accurate)!
See `DIFFICULTY_SCORE_GUIDE.md` for details.

### 2. Detect Sub-Questions (New!)
```bash
python detect_sub_questions.py
```
Detects sub-questions (a), i., ii.) that follow numbered questions.
See `SUB_QUESTION_GUIDE.md` for details.

### 3. Detect Translation & OCR Issues (New!)
```bash
python detect_translation_issues.py
```
Identifies translation questions with poor OCR quality (especially Arabic).
Marks questions that need re-extraction with proper language support.
See `OCR_RE_EXTRACTION_GUIDE.md` for fixing instructions.

### 4. Explore Your Data (Recommended!)
```bash
# Open the exploratory analysis notebook
jupyter notebook notebooks/exploratory_analysis.ipynb
# OR open it directly in VS Code/PyCharm
```
This comprehensive notebook helps you understand your data before building models.
See `notebooks/HOW_TO_USE_EDA.md` for a detailed guide.

### 5. Check Your Data (Quick Overview)
```bash
python models/check_current_data.py
```
This shows a quick summary of your dataset.

### 6. Clean Your Data (Recommended)
```bash
python exam_analysis/run_cleaning.py
```
Prepares data for machine learning by removing noise and duplicates.

### 7. Build Your First Model
```bash
python models/build_first_model.py
```
Trains initial models for:
- Question type classification
- Difficulty prediction

### 8. Read the Model Building Guide
See `models/README.md` (formerly MODEL_BUILDING_GUIDE.md) for:
- Step-by-step model building process
- When to download more exams
- Advanced techniques
- Best practices

## ğŸ“Š Current Dataset

- **13 exams** from various courses
- **201 questions** extracted and analyzed
- **Question types**: Essay (25%), Short Answer (19%), Numerical (8%), True/False (7%), Other (41%)
- **Courses**: ARAB100, ECON310-435, ELEC252-372

## ğŸ¯ Next Steps

1. **Explore your data** - Run the EDA notebook to understand what you have
2. **Clean your data** - Run the cleaning pipeline to prepare for ML
3. **Build first models** - Start with simple classification
4. **Evaluate results** - See what works and what doesn't
5. **Iterate** - Improve models based on results
6. **Then scale up** - Download more exams if needed

**Detailed Workflow**:
```
1. Run EDA notebook â†’ Understand your data
2. Run data cleaning â†’ Remove noise and duplicates  
3. Build first model â†’ Test your approach
4. Evaluate â†’ Identify improvements
5. Iterate â†’ Improve models
6. Scale up â†’ Download more data if needed
```

## ğŸ“š Documentation

- **`docs/TEXT_EXTRACTION_GUIDE.md`** - **NEW!** How to extract words/text from PDFs
- **`docs/COVER_PAGE_EXTRACTION_GUIDE.md`** - Cover page metadata extraction & context-based OCR
- **`FEATURES_SUMMARY.md`** - Overview of difficulty scores and sub-question detection
- **`DIFFICULTY_SCORE_GUIDE.md`** - How difficulty scores are calculated
- **`SUB_QUESTION_GUIDE.md`** - How sub-questions are detected
- **`OCR_RE_EXTRACTION_GUIDE.md`** - How to fix Arabic/translation OCR issues
- **`notebooks/HOW_TO_USE_EDA.md`** - Step-by-step guide to exploratory analysis
- **`models/README.md`** - Complete guide to building ML models
- **`docs/PROJECT_GOALS.md`** - Project vision and objectives
- **`docs/IMPLEMENTATION_ROADMAP.md`** - Detailed implementation steps
- **`exam_analysis/DATA_CLEANING_GUIDE.md`** - Data cleaning guide

## ğŸ› ï¸ Requirements

- Python 3.9+
- See `requirements.txt` for all dependencies

Install dependencies:
```bash
pip install -r requirements.txt
```

Key ML packages:
- scikit-learn (classification, regression)
- pandas (data manipulation)
- numpy (numerical operations)
- transformers (optional, for advanced NLP)

## ğŸ“ Workflow

```
1. Data Extraction (DONE âœ…)
   â””â”€â”€ exam_analysis.json created

2. Extract Cover Page Metadata (NEW! âœ…)
   â””â”€â”€ Run: python extract_cover_page_metadata.py
   â””â”€â”€ Extracts: faculty, professor, dates, total marks, OCR config

3. Data Cleaning
   â””â”€â”€ Run: python exam_analysis/run_cleaning.py
   â””â”€â”€ Output: exam_analysis_cleaned.json

4. Calculate Difficulty Scores
   â””â”€â”€ Run: python calculate_difficulty.py
   â””â”€â”€ Uses cover page total marks (more accurate!)

5. Model Building (CURRENT FOCUS)
   â””â”€â”€ Start: python models/build_first_model.py
   â””â”€â”€ Iterate based on results

6. Model Evaluation
   â””â”€â”€ Analyze accuracy, identify improvements

7. Scale Up (Future)
   â””â”€â”€ Download more exams if models work well
```

## ğŸ’¡ Key Decisions Made

- âœ… **Parsing/download code removed** - Focus on model building
- âœ… **Data organized** - Clean structure for ML workflow
- âœ… **Model building ready** - Starter scripts and guides provided

## ğŸ†˜ Getting Help

1. **Check the guide**: `models/README.md` has detailed explanations
2. **Review your data**: Run `models/check_current_data.py` to see what you have
3. **Start simple**: Use `models/build_first_model.py` as a starting point

## ğŸ“„ License

MIT License

---

**Ready to build ML models! ğŸš€**

**Recommended Start**: 
1. Run exploratory analysis: `jupyter notebook notebooks/exploratory_analysis.ipynb`
2. Read the guide: `notebooks/HOW_TO_USE_EDA.md`
3. Then proceed with data cleaning and model building
